
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Parameter Discovery in the 2D Burgers' Equation via Physics-Informed Neural Networks">
      
      
        <meta name="author" content="Eduardo Furlan">
      
      
        <link rel="canonical" href="https://efurlanm.github.io/burgers-pinn/research_update_appendix.html">
      
      
        <link rel="prev" href="index.html">
      
      
      
        
      
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Appendix A: Methodological Advances - From Specialist to Generalist Surrogate - Burgers PINN</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="assets/extra.css">
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#appendix-a-methodological-advances-from-specialist-to-generalist-surrogate" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Burgers PINN" class="md-header__button md-logo" aria-label="Burgers PINN" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Burgers PINN
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Appendix A: Methodological Advances - From Specialist to Generalist Surrogate
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
      <div class="md-header__source">
        <a href="http://github.com/efurlanm/burgers-pinn/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    burgers-pinn
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Burgers PINN" class="md-nav__button md-logo" aria-label="Burgers PINN" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Burgers PINN
  </label>
  
    <div class="md-nav__source">
      <a href="http://github.com/efurlanm/burgers-pinn/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    burgers-pinn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Parameter Discovery in the 2D Burgers' Equation via Physics-Informed Neural Networks
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Appendix A: Methodological Advances - From Specialist to Generalist Surrogate
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="research_update_appendix.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Appendix A: Methodological Advances - From Specialist to Generalist Surrogate
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.1. Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a2-evolution-of-the-modeling-paradigm" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.2. Evolution of the Modeling Paradigm
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a3-computational-optimization-for-scale" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.3. Computational Optimization for Scale
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A.3. Computational Optimization for Scale">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a31-memory-bound-regime-and-internal-batching" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.3.1. Memory-Bound Regime and Internal Batching
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a32-nested-gradient-tapes-for-stability" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.3.2. Nested Gradient Tapes for Stability
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a4-sampling-strategies-and-robustness" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.4. Sampling Strategies and Robustness
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A.4. Sampling Strategies and Robustness">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a41-the-failure-of-random-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.4.1. The Failure of Random Sampling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a42-stabilization-via-latin-hypercube-sampling-lhs" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.4.2. Stabilization via Latin Hypercube Sampling (LHS)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a43-focused-optimization-best-case-refinement" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.4.3. Focused Optimization (Best Case Refinement)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a5-conclusion-the-virtual-sensor" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.5. Conclusion: The Virtual Sensor
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a6-references" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.6. References
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.1. Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a2-evolution-of-the-modeling-paradigm" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.2. Evolution of the Modeling Paradigm
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a3-computational-optimization-for-scale" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.3. Computational Optimization for Scale
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A.3. Computational Optimization for Scale">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a31-memory-bound-regime-and-internal-batching" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.3.1. Memory-Bound Regime and Internal Batching
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a32-nested-gradient-tapes-for-stability" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.3.2. Nested Gradient Tapes for Stability
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a4-sampling-strategies-and-robustness" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.4. Sampling Strategies and Robustness
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A.4. Sampling Strategies and Robustness">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a41-the-failure-of-random-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.4.1. The Failure of Random Sampling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a42-stabilization-via-latin-hypercube-sampling-lhs" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.4.2. Stabilization via Latin Hypercube Sampling (LHS)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a43-focused-optimization-best-case-refinement" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.4.3. Focused Optimization (Best Case Refinement)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a5-conclusion-the-virtual-sensor" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.5. Conclusion: The Virtual Sensor
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a6-references" class="md-nav__link">
    <span class="md-ellipsis">
      
        A.6. References
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="appendix-a-methodological-advances-from-specialist-to-generalist-surrogate">Appendix A: Methodological Advances - From Specialist to Generalist Surrogate</h1>
<p><strong>Document Status:</strong> Post-Submission Research Report (CIACA 2025)<br />
<strong>Scope:</strong> Advanced Computational Optimization and Sampling Strategies for PINNs</p>
<h2 id="a1-introduction">A.1. Introduction</h2>
<p>Following the acceptance of the original article "Parameter Discovery in the 2D Burgers' Equation", subsequent research focused on overcoming the <strong>"instance-specific" limitation</strong> identified in the conclusion. The research evolved from a <strong>Specialist Model</strong> (proof of concept, single <span class="arithmatex">\(\nu\)</span>) to a <strong>Generalist Surrogate Model</strong> capable of parametric inference for <span class="arithmatex">\(\nu \in [0.01, 0.1]\)</span>. This appendix details the computational optimizations and sampling strategies required to scale the solution, shifting the problem from "Controlled Overfitting" to "Efficient Generalization".</p>
<h2 id="a2-evolution-of-the-modeling-paradigm">A.2. Evolution of the Modeling Paradigm</h2>
<p>The original approach required mandatory retraining for any new physical parameter. The new <strong>Surrogate V2</strong> architecture treats the kinematic viscosity <span class="arithmatex">\(\nu\)</span> not just as a coefficient in the PDE loss, but as an input feature to the neural network <span class="arithmatex">\(f(x, y, t, \nu) \rightarrow (u, v)\)</span>, effectively learning the operator of the equation.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Specialist Model (Article)</th>
<th style="text-align: left;">Surrogate Model (Current)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Objective</strong></td>
<td style="text-align: left;">Fit one specific instance (<span class="arithmatex">\(\nu=0.05\)</span>)</td>
<td style="text-align: left;">Generalize for <span class="arithmatex">\(\nu \in [0.01, 0.1]\)</span></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Training Data</strong></td>
<td style="text-align: left;">Single Dataset</td>
<td style="text-align: left;">Multi-Dataset (19 simulations)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Inference Time</strong></td>
<td style="text-align: left;">~520s (Retraining)</td>
<td style="text-align: left;"><strong>&lt; 60s (Direct Inference)</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Metric</strong></td>
<td style="text-align: left;">Reconstruction Error (Training)</td>
<td style="text-align: left;">Generalization Error (Unseen Data)</td>
</tr>
</tbody>
</table>
<h2 id="a3-computational-optimization-for-scale">A.3. Computational Optimization for Scale</h2>
<p>Scaling to multi-dataset training introduced severe memory bottlenecks on the reference hardware (NVIDIA RTX 3050, 6GB VRAM).</p>
<h3 id="a31-memory-bound-regime-and-internal-batching">A.3.1. Memory-Bound Regime and Internal Batching</h3>
<p>Profiling with <strong>NVIDIA Nsight Compute</strong> (<code>ncu</code>) revealed that the training process was <strong>Memory-Bound</strong>, dominated by data transfer latency rather than arithmetic intensity. The predominance of element-wise operations on large batches saturated the memory bandwidth.</p>
<ul>
<li><strong>Optimization:</strong> We implemented <em>internal batching</em> for the PDE residual evaluation, reducing the <code>pde_batch_size</code> from 20,000 to <strong>4,096</strong>.</li>
<li><strong>Result:</strong> This yielded measurable gains:</li>
<li><strong>L2 Cache Hit Rate:</strong> Increased by <strong>~16%</strong>.</li>
<li><strong>Global Memory Traffic:</strong> Reduced by <strong>~67%</strong> (mitigating cache thrashing).</li>
<li><strong>Training Time:</strong> Estimated <strong>~2x reduction</strong> in Stage 1 training time.</li>
</ul>
<h3 id="a32-nested-gradient-tapes-for-stability">A.3.2. Nested Gradient Tapes for Stability</h3>
<p>Calculating second-order derivatives (<span class="arithmatex">\(u_{xx}, u_{yy}\)</span>) for the Navier-Stokes/Burgers residual is computationally expensive. The standard implementation using persistent <code>tf.GradientTape</code> caused systematic <strong>Out-Of-Memory (OOM)</strong> errors due to excessive retention of the computational graph.</p>
<ul>
<li><strong>Solution:</strong> We implemented <strong>Nested Gradient Tapes</strong> with explicit resource release. This reduced the spatial complexity of the automatic differentiation graph, preventing VRAM saturation during the backward pass.</li>
</ul>
<h2 id="a4-sampling-strategies-and-robustness">A.4. Sampling Strategies and Robustness</h2>
<h3 id="a41-the-failure-of-random-sampling">A.4.1. The Failure of Random Sampling</h3>
<p>Initial experiments with random sampling (Ensemble of 10 seeds) for the Surrogate V2 model showed high instability. While the best case (Seed 7) achieved a generalization error of <strong>3.54%</strong>, the worst cases diverged to <strong>162%</strong>, with a high standard deviation (<span class="arithmatex">\(\sigma \approx 57.87\%\)</span>).</p>
<ul>
<li><strong>Failure Analysis:</strong> The optimizer in Stage 2 (Inverse Problem) was often "deceived" by the neural network. The loss surface learned by the surrogate contained spurious gradients that pushed the solution to the physical domain boundary (<span class="arithmatex">\(\nu \approx 0.1\)</span>) when trained on sparse data.</li>
</ul>
<h3 id="a42-stabilization-via-latin-hypercube-sampling-lhs">A.4.2. Stabilization via Latin Hypercube Sampling (LHS)</h3>
<p>To ensure uniform coverage of the parameter space <span class="arithmatex">\(\nu\)</span>, we replaced random sampling with <strong>Latin Hypercube Sampling (LHS)</strong>.</p>
<ul>
<li><strong>Method:</strong> LHS stratifies the input probability distributions, ensuring that each portion of the parameter range is sampled exactly once.</li>
<li><strong>Results (Ensemble Statistics):</strong></li>
<li><strong>Mean Error:</strong> Reduced from 74.07% to <strong>20.56%</strong> (~3.6x improvement).</li>
<li><strong>Stability:</strong> Standard deviation reduced by ~2.7x (from 57.87% to 21.46%).</li>
<li><strong>Critical Failures:</strong> LHS eliminated the divergence scenarios where error exceeded 100%.</li>
</ul>
<h3 id="a43-focused-optimization-best-case-refinement">A.4.3. Focused Optimization (Best Case Refinement)</h3>
<p>To test the limit of the architecture, we extended the training of the best LHS candidate (Seed 2) from 6,000 to <strong>15,000 epochs</strong>.</p>
<ul>
<li><strong>Result:</strong> The generalization error dropped from 2.63% to <strong>2.53%</strong> (-3.61% relative improvement). This confirms that the surrogate model quality is the limiting factor for inference accuracy.</li>
</ul>
<h2 id="a5-conclusion-the-virtual-sensor">A.5. Conclusion: The Virtual Sensor</h2>
<p>The research successfully transformed the PINN from a single-instance solver into a <strong>Virtual Sensor</strong>. Although the initial training cost is higher (~19 min vs ~8.7 min for the Specialist), the surrogate model enables <strong>instantaneous inference</strong> (<span class="arithmatex">\(&lt; 47s\)</span>) of physical parameters for new, unseen flows without retraining. The combination of <strong>Memory-Bound optimizations</strong> and <strong>LHS sampling</strong> was decisive in making this approach viable on constrained hardware.</p>
<h2 id="a6-references">A.6. References</h2>
<ol>
<li><strong>Abadi, M. et al. (2015).</strong> TensorFlow: Large-scale machine learning on heterogeneous distributed systems. <em>arXiv preprint arXiv:1603.04467</em>.</li>
<li><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016).</strong> <em>Deep Learning</em>. MIT Press.</li>
<li><strong>Wang, S., Teng, Y., &amp; Perdikaris, P. (2021).</strong> Understanding and mitigating gradient flow pathologies in physics-informed neural networks. <em>SIAM Journal on Scientific Computing</em>.</li>
<li><strong>McKay, M. D. et al. (1979).</strong> Comparison of three methods for selecting values of input variables in the analysis of output from a computer code. <em>Technometrics</em>. (Context: Latin Hypercube Sampling).</li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      CC BY 4.0 License
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": ".", "features": ["header.autohide"], "search": "assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="assets/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>